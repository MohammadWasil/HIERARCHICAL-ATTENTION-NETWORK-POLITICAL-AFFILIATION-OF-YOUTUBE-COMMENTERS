EPOCHS: 240
BATCH_SIZE: 16
NUM_CLASS: 2
EMBEDDING_SIZE: 100
DECODER_HIDDEN_DIM_HAN: 8
ENCODER_HIDDEN_DIM_HAN: 8
HIDDEN_DIM_LSTM: 8
USE_PRETRAINED_EMBEDDING_MATRIX: True
lr: 0.0001 # after 120, it was changed to 0.001
BATCH_SAMPLER: False # it is better to keep this false.

PATH_TO_SAVE_VOCAB_HAN: "./Vocabulary/Vocab HAN.pt.tar"
PATH_TO_SAVE_MODEL_HAN: "./Han Models/Model HAN Epoch {}.pt.tar"
LAST_SAVED_EPOCH_HAN_MODEL: 212 #Null # keep on updating this whenever you have new model and need to resume train.

PATH_TO_SAVE_VOCAB_LSTM: "./Vocabulary/Vocab LSTM.pt.tar"
PATH_TO_SAVE_MODEL_LSTM: "./LSTM Models/Model LSTM Epoch {}.pt.tar"
LAST_SAVED_EPOCH_LSTM_MODEL: #Null # keep on updating this whenever you have new model and need to resume train.