{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "class CommentDataset(Dataset):\n",
    "    def __init__(self, folder_path, train=False, test=False, valid=False):\n",
    "        \n",
    "        if (train==False and test==False and valid==False):\n",
    "            raise Exception('One of the `train`, `test` or `valid` needs to be True, got `train = {}` `test = {}` and `valid = {}`'.format(train, test, valid))\n",
    "        if (train==True and test==True and valid == True):\n",
    "            raise Exception('Only one of the `train`, `test` or `valid` needs to be True, got `train = {}` `test = {}` and `valid = {}`'.format(train, test, valid))\n",
    "        if (train==True and test==True):\n",
    "            raise Exception('Only one of the `train` or `test` needs to be True, got `train = {}`, and `test = {}`'.format(train, test))\n",
    "        if (train==True and valid==True):\n",
    "            raise Exception('Only one of the `train` or `valid` needs to be True, got `train = {}`, and `valid = {}`'.format(train, valid))\n",
    "        if (test==True and valid==True):\n",
    "            raise Exception('Only one of the `test` or `valid` needs to be True, got `test = {}`, and `valid = {}`'.format(test, valid))\n",
    "\n",
    "        self.train_df = None\n",
    "        self.test_df = None\n",
    "        self.valid_df = None\n",
    "\n",
    "        # boolean values\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        self.valid = valid\n",
    "\n",
    "        self.data_selected = None\n",
    "        self.comment_selected = None\n",
    "    \n",
    "        self.train_comment = []\n",
    "        self.test_comment = []\n",
    "        self.val_comment = []\n",
    "    \n",
    "        # Read the dataset\n",
    "        self.data = pd.read_csv(folder_path, sep = \",\")#.head(20)\n",
    "        \n",
    "        self.data = shuffle(self.data)\n",
    "        self.data.reset_index(inplace=True, drop=True)\n",
    "        \n",
    "        self.data['Annot'].replace('LEFT', 0, inplace=True)\n",
    "        self.data['Annot'].replace('RIGHT', 1, inplace=True)\n",
    "        \n",
    "        # split the dataset into train, test, and valid.\n",
    "        self.train_df, test_df = train_test_split(self.data, test_size=0.2,  random_state=11)\n",
    "        self.test_df, self.valid_df = train_test_split(test_df, test_size=0.5,  random_state=96)\n",
    "        \n",
    "        # a basic preprocessor, beeds to be done  outside the dataset function.\n",
    "        #idx = [4, 7, 12, 19]\n",
    "        #list_d = []\n",
    "        #for i in range(len(self.data[\"comment\"])):\n",
    "        #    if i not in idx:\n",
    "        #        d = self.data[\"comment\"][i].split(\"', \")\n",
    "        #        list_d.append(d)\n",
    "        #    else:\n",
    "        #        d = self.data[\"comment\"][i].split(\"\\\", \")\n",
    "        #        list_d.append(d)\n",
    "        \n",
    "        if self.train == True:\n",
    "            # do the sorting\n",
    "            # Sort the dataframe according to the number of comments on documents.\n",
    "            self.train_df.sort_values(by=['Number of Comment'], ascending=False, inplace=True)       \n",
    "            comments = []\n",
    "            for com in self.train_df[\"comment\"]:\n",
    "                comments.append(com.split(\"-|-\")[:-1])\n",
    "            self.train_comment = comments\n",
    "        elif self.test == True:\n",
    "            # no need to sort\n",
    "            comments = []\n",
    "            for com in self.test_df[\"comment\"]:\n",
    "                comments.append(com.split(\"-|-\")[:-1])\n",
    "            self.test_comment = comments\n",
    "        elif self.valid == True:\n",
    "            # no need to sort\n",
    "            comments = []\n",
    "            for com in self.valid_df[\"comment\"]:\n",
    "                comments.append(com.split(\"-|-\")[:-1])\n",
    "            self.val_comment = comments\n",
    "        \n",
    "        \n",
    "        # split the dataset into train, test, and valid.\n",
    "        #self.train_df, test_df = train_test_split(self.data, test_size=0.2,  random_state=11)\n",
    "        #self.test_df, self.valid_df = train_test_split(test_df, test_size=0.5,  random_state=96)\n",
    "\n",
    "        #if self.train == True:\n",
    "        # do the sorting\n",
    "        #self.train_df[\"combined_text_len\"] = 0\n",
    "        #for i, row in self.train_df.iterrows():\n",
    "        #    self.train_df.at[i, \"combined_text_len\"] = len(tokenizer(row[\"combined_text\"]))\n",
    "        # Sort the dataframe according to the length of the sentence\n",
    "        #self.train_df.sort_values(by=['combined_text_len'], ascending=False, inplace=True)            \n",
    "        #elif self.test == True:\n",
    "            # no need ot sort\n",
    "        #    self.test_df = self.test_df\n",
    "        #elif self.valid == True:\n",
    "            # no need ot sort\n",
    "        #    self.valid_df = self.valid_df\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.train == True:\n",
    "            self.data_selected = self.train_df\n",
    "            self.comment_selected = self.train_comment\n",
    "\n",
    "        elif self.test == True:\n",
    "            self.data_selected = self.test_df\n",
    "            self.comment_selected = self.test_comment\n",
    "\n",
    "        elif self.valid == True:\n",
    "            self.data_selected = self.valid_df\n",
    "            self.comment_selected = self.val_comment\n",
    "\n",
    "        label = self.data_selected.iloc[idx][\"Annot\"]\n",
    "        sentence = self.comment_selected[idx]\n",
    "        return sentence, label\n",
    "\n",
    "    def __len__(self):\n",
    "        \n",
    "        \n",
    "        if self.train == True:\n",
    "            len_ = len(self.train_comment)\n",
    "\n",
    "        elif self.test == True:\n",
    "            len_ = len(self.test_comment)\n",
    "\n",
    "        elif self.valid == True:\n",
    "            len_ = len(self.val_comment)\n",
    "        \n",
    "        \n",
    "        #if self.train == True:\n",
    "        #len_ = len(self.comment)\n",
    "\n",
    "        #elif self.test == True:\n",
    "        #    len_ = len(self.test_df)\n",
    "\n",
    "        #elif self.valid == True:\n",
    "        #    len_ = len(self.valid_df)\n",
    "        return len_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"12. Subscription Training Data.csv\"\n",
    "\n",
    "dataset_train = CommentDataset(data_folder, train=True, test=False, valid=False)\n",
    "dataset_test = CommentDataset(data_folder, train=False, test=True, valid=False)\n",
    "dataset_valid = CommentDataset(data_folder, train=False, test=False, valid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens(data_iter):\n",
    "    for iter_, _ in data_iter:\n",
    "        for sentence in iter_:\n",
    "            yield tokenizer(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vocabulary from the training data.\n",
    "vocab = build_vocab_from_iterator(yield_tokens(dataset_train), specials=[\"<unk>\"])\n",
    "vocab.set_default_index(vocab[\"<unk>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32592"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(vocab.get_itos()) # len(vocab.get_stoi()) - length of the vocabulary\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: vocab(tokenizer(x))\n",
    "label_pipeline = lambda x: int(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# works perfectly. backup\n",
    "def collate_batch(batch):\n",
    "    label_list, text_list = [], []\n",
    "    for (_text, _label) in batch:\n",
    "        \n",
    "        label_list.append(torch.tensor(label_pipeline(_label), dtype=torch.int64 ))\n",
    "        \n",
    "        texts = []\n",
    "        for t in _text:\n",
    "            texts.append(torch.tensor(text_pipeline(t), dtype=torch.int64))\n",
    "        text_list.append(texts)\n",
    "    \n",
    "    sentence_length, word_length = get_max_length(text_list)\n",
    "    \n",
    "    # get the maximum length of the sentence from every batch\n",
    "    #max_len_sent=0\n",
    "    #for t in text_list:\n",
    "    #    for t_i in t:\n",
    "    #        if t_i.shape[0] > max_len_sent:\n",
    "    #            max_len_sent = t_i.shape[0]\n",
    "    \n",
    "    text_list_p = []\n",
    "    for t in text_list:\n",
    "        # input shape: a list of tensors with unequal length of sentences.\n",
    "        # padding to the highest length of the sequence.\n",
    "        p = [ torch.cat((batch, torch.LongTensor([vocab_size-1]).repeat(word_length - len(batch))), dim=0) \n",
    "                if((word_length - batch.shape[0]) !=  0 ) else batch for batch in t]\n",
    "        \n",
    "        # input shape: a list of tensors with unequal length of documents.\n",
    "        # padding to the highest length of the document.\n",
    "        if(sentence_length - len(p)) !=  0:\n",
    "            extended_sentences = [torch.LongTensor([vocab_size-1 for _ in range(word_length)] )\n",
    "                                  for _ in range(sentence_length - len(p))]\n",
    "            p.extend(extended_sentences)\n",
    "\n",
    "            #p = pad_sequence(text_list[0], batch_first=False, padding_value = vocab_size-1)\n",
    "            #  OUTPUT shape: [MAX_LENGTH_OF_THE_SENTENCE_IN_BATCH, NUM_SENTENCES] => [57, 5]\n",
    "        \n",
    "        p = torch.stack(p)\n",
    "        # OUTPUT shape: [NUM_SENTENCES X MAX_LENGTH_OF_THE_SENTENCE_IN_BATCH] => [5,57]\n",
    "        text_list_p.append(p) # for every batch\n",
    "    \n",
    "    text_list_p = torch.stack(text_list_p)\n",
    "    # OUTPUT shape: [BATCH_SIZE X NUM_SENTENCES X MAX_LENGTH_OF_THE_SENTENCE_IN_DOCUMENT ] => [3, 5, 57]\n",
    "\n",
    "    #text_list_p = torch.permute(text_list_p, (2, 1, 0))\n",
    "    # NOt sure, whether it should be this: OUTPUT shape: [MAX_LENGTH_OF_THE_SENTENCE_IN_BATCH X NUM_SENTENCES X BATCH_SIZE] => [57, 5, 2]\n",
    "    \n",
    "    # convert a list of tensors to tensors.\n",
    "    # input : a list of tensors of len BATCH_SIZE\n",
    "    label_list = torch.stack(label_list)   \n",
    "    # OUTPUT shape: [BATCH_SIZE]\n",
    "    \n",
    "    return text_list_p.to(device), label_list.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the maximum number of sentences in a document, and maximum number of words in sentences.\n",
    "def get_max_length(doc):\n",
    "    \"\"\"\n",
    "    doc = [\n",
    "        [\n",
    "                [1,2,3,4,5],\n",
    "               [1,2,3,4],\n",
    "               [1,2,3,4,5,6,7,8],\n",
    "               [1,2,3,4,5]\n",
    "        ], \n",
    "        [\n",
    "                [1,2],\n",
    "               [1,2,3,4,5,6,7,8,9],\n",
    "               [1,2,3,4,5],\n",
    "               [1,2,3,4],\n",
    "                [1, 2,3,4,5,6]\n",
    "        ]\n",
    "    ]\n",
    "\n",
    "    #sentence_in_doc, word_in_sentence = get_max_length(doc)\n",
    "    sentence_in_doc -> 5, and word_in_sentence -> 9\n",
    "    \"\"\"\n",
    "    \n",
    "    sent_length_list = []\n",
    "    word_length_list = []\n",
    "\n",
    "    for sent in doc:\n",
    "        sent_length_list.append(len(sent))\n",
    "\n",
    "        for word in sent:\n",
    "            word_length_list.append(len(word))\n",
    "\n",
    "    sorted_word_length = sorted(word_length_list)\n",
    "    sorted_sent_length = sorted(sent_length_list)\n",
    "    \n",
    "    #return sorted_sent_length[int(0.8*len(sorted_sent_length))], sorted_word_length[int(0.8*len(sorted_word_length))]\n",
    "    return sorted_sent_length[-1], sorted_word_length[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH SAMPLER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import BatchSampler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import BatchSampler\n",
    "import numpy as np\n",
    "\n",
    "class YoutubeBatchSampler(BatchSampler):\n",
    "    def __init__(self, dataset, num_of_liberals, num_of_conservatives):\n",
    "        \n",
    "        self.label_list = []\n",
    "        for _, label in dataset:\n",
    "            self.label_list.append(label)\n",
    "\n",
    "        self.label_list = torch.LongTensor(self.label_list) # list of all the labels in the dataset\n",
    "        \n",
    "        self.label_set = list(set(self.label_list.numpy())) # unique labels from the dataset\n",
    "\n",
    "        self.label_to_indices = {label: np.where(self.label_list.numpy() == label)[0]\n",
    "                                 for label in self.label_set}\n",
    "\n",
    "        for l in self.label_set:\n",
    "            np.random.shuffle(self.label_to_indices[l])\n",
    "\n",
    "        self.used_label_indices_count = {label: 0 for label in self.label_set}\n",
    "        self.count = 0\n",
    "        self.dataset = dataset\n",
    "        self.num_of_liberals = num_of_liberals\n",
    "        self.num_of_conservatives = num_of_conservatives\n",
    "        self.batch_size = self.num_of_liberals + self.num_of_conservatives\n",
    "\n",
    "    def __iter__(self):\n",
    "        self.count = 0\n",
    "        \n",
    "        # maybe add <= \n",
    "        while self.count + self.batch_size < len(self.dataset):\n",
    "            classes = np.array([1, 0])\n",
    "            indices = []\n",
    "            for class_ in classes:\n",
    "                if(class_ == 0) :\n",
    "                    indices.extend(self.label_to_indices[class_][self.used_label_indices_count[class_] : self.used_label_indices_count[class_] + self.num_of_liberals])\n",
    "                    self.used_label_indices_count[class_] += self.num_of_liberals\n",
    "\n",
    "                    if self.used_label_indices_count[class_] + self.num_of_liberals > len(self.label_to_indices[class_]):\n",
    "                        np.random.shuffle(self.label_to_indices[class_])\n",
    "                        self.used_label_indices_count[class_] = 0\n",
    "              \n",
    "                elif(class_ == 1):\n",
    "                    indices.extend(self.label_to_indices[class_][self.used_label_indices_count[class_] : self.used_label_indices_count[class_] + self.num_of_conservatives])\n",
    "                    self.used_label_indices_count[class_] += self.num_of_conservatives\n",
    "\n",
    "                    if self.used_label_indices_count[class_] + self.num_of_conservatives > len(self.label_to_indices[class_]):\n",
    "                        np.random.shuffle(self.label_to_indices[class_])\n",
    "                        self.used_label_indices_count[class_] = 0\n",
    "              \n",
    "              \n",
    "            yield indices\n",
    "            self.count = self.count + self.num_of_conservatives + num_of_liberals\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.dataset) // self.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "#num_of_liberals = int(BATCH_SIZE / 2)\n",
    "#num_of_conservatives = int(BATCH_SIZE - num_of_liberals)\n",
    "#batch_sampler_train = YoutubeBatchSampler(dataset_train, num_of_liberals, num_of_conservatives)\n",
    "train_dataloader = DataLoader(dataset_train, batch_size=BATCH_SIZE,\n",
    "                              shuffle=False, collate_fn=collate_batch)\n",
    "val_dataloader = DataLoader(dataset_valid,\n",
    "                              shuffle=False, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(dataset_test,\n",
    "                              shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, VOCAB_SIZE, EMBEDDING_DIMENSION, num_class, ENCODER_HIDDEN_DIMENSION, DECODER_HIDDEN_DIMENSION, embedding_matrix):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.vocab_size = VOCAB_SIZE\n",
    "        self.embed_dim = EMBEDDING_DIMENSION\n",
    "        \n",
    "        self.encoder_hidden_dim = ENCODER_HIDDEN_DIMENSION\n",
    "        self.decoder_hidden_dim = DECODER_HIDDEN_DIMENSION\n",
    "        \n",
    "        self.num_class = num_class\n",
    "\n",
    "        if USE_PRETRAINED_EMBEDDING_MATRIX:\n",
    "            self.vocab_size = embedding_matrix.shape[0]\n",
    "            self.embed_dim = embedding_matrix.shape[1]\n",
    "            \n",
    "            self.embedding = nn.Embedding(num_embeddings = self.vocab_size, embedding_dim = self.embed_dim)\n",
    "            self.embedding.weight=nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
    "        else:\n",
    "            self.embedding = nn.Embedding(self.vocab_size, self.embed_dim)\n",
    "        \n",
    "        self.gru = nn.GRU(self.embed_dim, self.encoder_hidden_dim, bidirectional =True)\n",
    "\n",
    "        self.attention = Attention(self.encoder_hidden_dim*2)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        # input shape: [MAX_LENGTH_OF_THE_SENTENCE_IN_BATCH X NUM_SENTENCES X BATCH_SIZE] \n",
    "        # or input shape: [MAX_LENGTH_OF_THE_SENTENCE_IN_BATCH X NUM_SENTENCES] \n",
    "        embedded = self.embedding(text)\n",
    "        # output shape: [MAX_LENGTH_OF_THE_SENTENCE_IN_BATCH X NUM_SENTENCES X EMBEDDING_DIMENSION]\n",
    "        # 2nd output: [BATCH_SIZE, MAX_LENGTH_OF_THE_SENTENCE_IN_DOC X 100]\n",
    "        \n",
    "        # input shape: [MAX_LENGTH_OF_THE_SENTENCE_IN_BATCH X NUM_SENTENCES x EMBEDDING_DIMENSION]\n",
    "        gru_out, hidden = self.gru(embedded)\n",
    "        # gru_out shape: [MAX_LENGTH_OF_THE_SENTENCE_IN_BATCH, NUM_SENTENCES, ENCODER_HIDDEN_DIMENSION*2]\n",
    "        # hidden[0] shape: [1, NUM_SENTENCES, ENCODER_HIDDEN_DIMENSION]\n",
    "        # hidden[1] shape: [1, NUM_SENTENCES, ENCODER_HIDDEN_DIMENSION]\n",
    "        \n",
    "        # 2nd gru_out shape: [BATCH_SIZE, MAX_LENGTH_OF_THE_SENTENCE_IN_DOC, ENCODER_HIDDEN_DIMENSION*2]\n",
    "        # 2nd hidden shape: [BATCH_SIZE, MAX_LENGTH_OF_THE_SENTENCE_IN_DOC, ENCODER_HIDDEN_DIMENSION]\n",
    "        \n",
    "        # concatenate both forward and backward hidden vectors\n",
    "        #hidden_f_b = torch.cat((hidden[0,:,:], hidden[1,:,:]), dim = 1)\n",
    "        # output shape: [NUM_SENTENCES, ENCODER_HIDDEN_DIMENSION*2]\n",
    "        \n",
    "\n",
    "        s_i = self.attention(gru_out) # fome the diagram, it is s_i.\n",
    "        \n",
    "        return s_i, gru_out\n",
    "\n",
    "class Sentence_Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, VOCAB_SIZE, EMBEDDING_DIMENSION, num_class, ENCODER_HIDDEN_DIMENSION, DECODER_HIDDEN_DIMENSION):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.vocab_size = VOCAB_SIZE\n",
    "        self.embed_dim = EMBEDDING_DIMENSION\n",
    "        \n",
    "        self.encoder_hidden_dim = ENCODER_HIDDEN_DIMENSION\n",
    "        self.decoder_hidden_dim = DECODER_HIDDEN_DIMENSION\n",
    "        \n",
    "        self.num_class = num_class\n",
    "        \n",
    "        #self.embedding = nn.Embedding(self.vocab_size, self.embed_dim)\n",
    "        \n",
    "        self.gru = nn.GRU(self.encoder_hidden_dim*2, self.encoder_hidden_dim, bidirectional =True)\n",
    "\n",
    "        self.attention = Attention(self.encoder_hidden_dim*2)\n",
    "\n",
    "        #self.init_weights()\n",
    "        \n",
    "    def forward(self, word_embed):\n",
    "        # input shape: [BATCH X NUM_SENTENCES x EMBEDDING_DIMENSION*2]\n",
    "        gru_out, hidden = self.gru(word_embed)\n",
    "        # gru_out shape: [BATCH X NUM_SENTENCES x EMBEDDING_DIMENSION*2]\n",
    "        # hidden shape: [BATCH X NUM_SENTENCES x EMBEDDING_DIMENSION]\n",
    "        \n",
    "        # concatenate both forward and backward hidden vectors\n",
    "        #hidden_f_b = torch.cat((hidden[0,:,:], hidden[1,:,:]), dim = 1)\n",
    "        # output shape: [NUM_SENTENCES, ENCODER_HIDDEN_DIMENSION*2]\n",
    "        \n",
    "        v = self.attention(gru_out) # from the diagram, it is v.\n",
    "        # output: [BATCH X 1 X ENCODER_HIDDEN_DIMENSION*2]\n",
    "        return v, gru_out\n",
    "      \n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, ENCODER_HIDDEN_DIMENSION):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder_hidden_dim = ENCODER_HIDDEN_DIMENSION\n",
    "        \n",
    "        self.linear = nn.Linear(self.encoder_hidden_dim, self.encoder_hidden_dim)\n",
    "        self.context = nn.Linear(self.encoder_hidden_dim, 1)\n",
    "        \n",
    "    def forward(self, gru_out):\n",
    "        \n",
    "        # input: [MAX_LENGTH_OF_THE_SENTENCE_IN_BATCH, NUM_SENTENCES, ENCODER_HIDDEN_DIMENSION*2]\n",
    "        hidden_enc = self.linear(gru_out)\n",
    "        # output: [MAX_LENGTH_OF_THE_SENTENCE_IN_BATCH, NUM_SENTENCES, ENCODER_HIDDEN_DIMENSION*2]\n",
    "\n",
    "        # 2nd output shape: [BATCH_SIZE, MAX_LENGTH_OF_THE_SENTENCE_IN_DOC, ENCODER_HIDDEN_DIMENSION*2]\n",
    "    \n",
    "        \n",
    "        # input: [MAX_LENGTH_OF_THE_SENTENCE_IN_BATCH, NUM_SENTENCES, ENCODER_HIDDEN_DIMENSION*2]\n",
    "        u = torch.tanh(hidden_enc)\n",
    "        # output: [MAX_LENGTH_OF_THE_SENTENCE_IN_BATCH, NUM_SENTENCES, ENCODER_HIDDEN_DIMENSION*2]\n",
    "        \n",
    "        # 2nd output shape: [BATCH_SIZE, MAX_LENGTH_OF_THE_SENTENCE_IN_DOC, ENCODER_HIDDEN_DIMENSION*2]\n",
    "        \n",
    "        # input: [MAX_LENGTH_OF_THE_SENTENCE_IN_BATCH, NUM_SENTENCES, ENCODER_HIDDEN_DIMENSION*2]\n",
    "        context_vector = self.context(u)\n",
    "        # output: [MAX_LENGTH_OF_THE_SENTENCE_IN_BATCH, NUM_SENTENCES, 1]\n",
    "        \n",
    "        # 2nd output shape: [BATCH_SIZE, MAX_LENGTH_OF_THE_SENTENCE_IN_DOC, 1]\n",
    "        \n",
    "        # input: [MAX_LENGTH_OF_THE_SENTENCE_IN_BATCH, NUM_SENTENCES, 1]\n",
    "        alpha = F.softmax(context_vector, dim=1)\n",
    "        # output: [MAX_LENGTH_OF_THE_SENTENCE_IN_BATCH, NUM_SENTENCES, 1]\n",
    "        \n",
    "        # 2nd output shape: [BATCH_SIZE, MAX_LENGTH_OF_THE_SENTENCE_IN_DOC, 1]\n",
    "        \n",
    "        alpha=alpha.permute(0, 2, 1)\n",
    "        # 2nd output shape: [BATCH_SIZE, 1, MAX_LENGTH_OF_THE_SENTENCE_IN_DOC]\n",
    "        \n",
    "        a = alpha@gru_out  \n",
    "        # 2nd output shape: [BATCH_SIZE, 1, ENCODER_HIDDEN_DIMENSION*2]\n",
    "        return a\n",
    "    \n",
    "class HierarchicalAttentionNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self, VOCAB_SIZE, EMBEDDING_DIMENSION, num_class, ENCODER_HIDDEN_DIMENSION, DECODER_HIDDEN_DIMENSION, embedding_matrix):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.vocab_size = VOCAB_SIZE\n",
    "        self.embedding_size = EMBEDDING_DIMENSION\n",
    "        self.num_class = num_class\n",
    "        self.ENCODER_HIDDEN_DIMENSION = ENCODER_HIDDEN_DIMENSION\n",
    "        self.DECODER_HIDDEN_DIMENSION = DECODER_HIDDEN_DIMENSION\n",
    "        self.embedding_matrix = embedding_matrix\n",
    "\n",
    "        self.model = Encoder(vocab_size, embedding_size, num_class, ENCODER_HIDDEN_DIMENSION, DECODER_HIDDEN_DIMENSION, self.embedding_matrix).to(device)\n",
    "        self.sent_model = Sentence_Encoder(vocab_size, embedding_size, num_class, ENCODER_HIDDEN_DIMENSION, DECODER_HIDDEN_DIMENSION).to(device)\n",
    "        \n",
    "        self.linear = nn.Linear(self.ENCODER_HIDDEN_DIMENSION*2, self.num_class)\n",
    "        \n",
    "    def forward(self, text):\n",
    "        \n",
    "        text = text.permute(1, 0, 2)\n",
    "        word_a_list, word_s_list = [], []\n",
    "\n",
    "        # Iterate through all the sentences in every batch\n",
    "        for sent in text:\n",
    "            # input: [BATCH_SIZE, MAX_LENGTH_OF_THE_SENTENCE_IN_DOC]\n",
    "            word_s, gru_out = self.model(sent)\n",
    "            # output: word_s: [BATCH_SIZE, 1, ENCODER_HIDDEN_DIMENSION*2]\n",
    "\n",
    "            #word_a_list.append(word_a)\n",
    "            word_s_list.append(word_s)\n",
    "\n",
    "        word_s_list = torch.cat(word_s_list, dim=1)\n",
    "        # output: word_s: [BATCH_SIZE, NUM_SENTENCES, ENCODER_HIDDEN_DIMENSION*2]\n",
    "        \n",
    "        v, gru_out_sentence = self.sent_model(word_s_list)\n",
    "        # output v: # output: [BATCH X 1 X ENCODER_HIDDEN_DIMENSION*2]\n",
    "        # output gru_out_sentence: [BATCH X NUM_SENTENCES x EMBEDDING_DIMENSION*2]\n",
    "        \n",
    "        v_output = self.linear(v)\n",
    "        # v_output shape: [BATCH, 1, Num_classes]        \n",
    "        \n",
    "        classifier = F.softmax(v_output, dim=2).squeeze(1)\n",
    "        # classifier shape: [BATCH, 1, Num_classes]        \n",
    "        \n",
    "        return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Download_and_extract():\n",
    "    print(\"This might take some time...\")\n",
    "    print(\"Downloading...\")\n",
    "    os.system('wget https://nlp.stanford.edu/data/glove.840B.300d.zip')\n",
    "    \n",
    "    Extract()\n",
    "    \n",
    "def Extract():\n",
    "    print(\"Extracting...\")\n",
    "    # extract and save to the same directory.\n",
    "    with zipfile.ZipFile('glove.840B.300d.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall(\"./\")\n",
    "    print(\"Done!\")\n",
    "    \n",
    "def load_pretrained_embedding_matrix():\n",
    "    # Downloadin Glove word vector\n",
    "    # this might take some time........... ~5 mins.\n",
    "    if((os.path.isfile('glove.840B.300d.zip') == False)):\n",
    "        Download_and_extract()\n",
    "    elif((os.path.isfile('glove.840B.300d.zip') == True) and (os.path.isfile('glove.840B.300d.txt') == False)):\n",
    "         Extract()\n",
    "    else:\n",
    "        print(\"Already Downloaded and extracted!\")\n",
    "\n",
    "    #!wget https://nlp.stanford.edu/data/glove.840B.300d.zip\n",
    "    #!unzip glove.840B.300d.zip\n",
    "\n",
    "# https://github.com/MohammadWasil/Visual-Question-Answering-VQA/blob/master/2.%20Dataset%20Used%20in%20Training..ipynb\n",
    "def GloveModel(file_path, vocab):\n",
    "    embedding_index = {}\n",
    "    f = open(file_path,'r', encoding='utf8')\n",
    "    embedding_index = {}\n",
    "    print(\"Opened!\")\n",
    "\n",
    "    for j, line in enumerate(f):\n",
    "        splitLine = line.split(' ')\n",
    "        word = splitLine[0]\n",
    "        embedding = np.asarray(splitLine[1:], dtype='float32')\n",
    "        embedding_index[word] = embedding\n",
    "      \n",
    "    print(\"Done.\",len(embedding_index),\" words loaded!\")\n",
    "    EMBEDDING_DIM = 300\n",
    "    embedding_matrix = np.zeros((len(vocab.get_stoi()) + 1, EMBEDDING_DIM))\n",
    "    print(embedding_matrix.shape)\n",
    "\n",
    "    for index, word in enumerate(vocab.get_itos()):\n",
    "        embedding_vector = embedding_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "          # words not found in embedding index will be all-zeros.\n",
    "          embedding_matrix[index] = embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can change this accordingly.\n",
    "USE_PRETRAINED_EMBEDDING_MATRIX = False\n",
    "\n",
    "if USE_PRETRAINED_EMBEDDING_MATRIX:\n",
    "    # download an dextract the glove embedding if they're not.\n",
    "    load_pretrained_embedding_matrix()\n",
    "    # load the embedding matrix.\n",
    "    embedding_matrix = GloveModel(\"glove.840B.300d.txt\", vocab)\n",
    "else:\n",
    "    embedding_matrix = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 4.00 GiB total capacity; 3.49 GiB already allocated; 0 bytes free; 3.50 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-23c4e4a86126>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtrain_loss_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[0mtrain_loss_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhan_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-38-23c4e4a86126>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(han_model, train_dataloader)\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[0mpredicted_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhan_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredicted_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-37-4f291351bff6>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m             \u001b[1;31m# input: [BATCH_SIZE, MAX_LENGTH_OF_THE_SENTENCE_IN_DOC]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m             \u001b[0mword_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgru_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m             \u001b[1;31m# output: word_s: [BATCH_SIZE, 1, ENCODER_HIDDEN_DIMENSION*2]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-37-4f291351bff6>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;31m# input shape: [MAX_LENGTH_OF_THE_SENTENCE_IN_BATCH X NUM_SENTENCES x EMBEDDING_DIMENSION]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mgru_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedded\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[1;31m# gru_out shape: [MAX_LENGTH_OF_THE_SENTENCE_IN_BATCH, NUM_SENTENCES, ENCODER_HIDDEN_DIMENSION*2]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;31m# hidden[0] shape: [1, NUM_SENTENCES, ENCODER_HIDDEN_DIMENSION]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    848\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[1;32m--> 850\u001b[1;33m                              self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[0;32m    851\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    852\u001b[0m             result = _VF.gru(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 18.00 MiB (GPU 0; 4.00 GiB total capacity; 3.49 GiB already allocated; 0 bytes free; 3.50 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "num_class = 2\n",
    "embedding_size = 100\n",
    "ENCODER_HIDDEN_DIMENSION = 64\n",
    "DECODER_HIDDEN_DIMENSION = 32\n",
    "\n",
    "han_model = HierarchicalAttentionNetwork(vocab_size, embedding_size, num_class, ENCODER_HIDDEN_DIMENSION, DECODER_HIDDEN_DIMENSION).to(device)\n",
    "\n",
    "def train(han_model, train_dataloader):\n",
    "    optimizer = Adam(han_model.parameters(), 0.0001)\n",
    "    loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "    train_loss_list = []\n",
    "    val_loss_list = []\n",
    "    train_accu_list = []\n",
    "    val_accu_list = []\n",
    "\n",
    "    for epoch in range(0, 20):\n",
    "        han_model.train()\n",
    "        han_model.to(device)\n",
    "        train_loss = 0\n",
    "        \n",
    "        accuracy = 0\n",
    "        \n",
    "        for idx, (text, label) in enumerate(train_dataloader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            predicted_label = han_model(text)\n",
    "\n",
    "            loss = loss_function(predicted_label, label)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #prediction = predicted_label#.argmax(1)#.item()\n",
    "            actual = label.reshape(-1)\n",
    "            \n",
    "            predicted_label = torch.argmax(predicted_label, dim=1 ) \n",
    "            accuracy += torch.eq(predicted_label, actual).sum().item()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "        train_loss = train_loss / len(train_dataloader)\n",
    "        accuracy = accuracy * 100.0 / len(dataset_train)\n",
    "\n",
    "        EPOCH_VAL_ACC, EPOCH_VAL_LOSS, F1_score = evaluate(val_dataloader, han_model, loss_function)\n",
    "\n",
    "        print(f'Epoch: {epoch+1} | Train Loss: {train_loss} | Accuracy: {accuracy} | Val Accuracy: {EPOCH_VAL_ACC} | Val Loss: {EPOCH_VAL_LOSS} | F1 Score: {F1_score}')\n",
    "        train_loss_list.append(train_loss)\n",
    "        val_loss_list.append(EPOCH_VAL_LOSS)\n",
    "        train_accu_list.append(accuracy)\n",
    "        val_accu_list.append(EPOCH_VAL_ACC)\n",
    "        \n",
    "    return train_loss_list, val_loss_list, train_accu_list, val_accu_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(val_dataloader, model, loss_function):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total_count = 0\n",
    "\n",
    "    # for f1 score\n",
    "    prediction_labels = []\n",
    "    actual_labels = []\n",
    "\n",
    "    val_loss = 0\n",
    "\n",
    "    with torch.no_grad():    \n",
    "        for text, label in val_dataloader:\n",
    "            text = text.to(device)\n",
    "            label = label.to(device)\n",
    "            \n",
    "            # feed the validation text into the model, and get the probabilities.\n",
    "            predicted_label = model(text)\n",
    "\n",
    "            # calculate loss\n",
    "            loss = loss_function(predicted_label, label)\n",
    "            \n",
    "            # validation accuracy\n",
    "            actual = label.reshape(-1)\n",
    "            predicted_label = torch.argmax(predicted_label, dim=1 ) \n",
    "            correct += torch.eq(predicted_label, actual).sum().item()\n",
    "\n",
    "            # to cal f1 score.\n",
    "            prediction_labels.append(predicted_label)\n",
    "            actual_labels.append(actual)   \n",
    "\n",
    "            # convert probabilities into 0/1.\n",
    "            #predicted_label = torch.round(predicted_label).type(torch.int64)\n",
    "            \n",
    "            # count the number of correctly predicted labels.\n",
    "            #correct += torch.eq(predicted_label, label).sum().item()\n",
    "            \n",
    "            # get the total length of the sentences in val_dataloader\n",
    "            #total_count += label.size(0)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "        val_loss = val_loss / len(val_dataloader)\n",
    "\n",
    "        # convert unequal length of lists of tensors to on single tensors.\n",
    "        #actual_labels = torch.flatten(torch.stack(actual_labels)) \n",
    "        actual_labels = torch.cat(actual_labels).to('cpu')\n",
    "        #prediction_labels = torch.flatten(torch.stack(prediction_labels)) \n",
    "        prediction_labels = torch.cat(prediction_labels).to('cpu')\n",
    "\n",
    "        F1_score = f1_score(actual_labels, prediction_labels)\n",
    "        \n",
    "    \n",
    "    # returns the accuracy of the model\n",
    "    return correct * 100.0 / len(dataset_valid), val_loss, F1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss_list, val_loss_list, train_accu_list, val_accu_list = train(han_model, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "TEST_ACC, TEST_LOSS, F1_score = evaluate(test_dataloader, han_model, loss_function = nn.CrossEntropyLoss())\n",
    "print(\"The test accuracy is: {:.2f}%\".format(TEST_ACC))\n",
    "print(\"F1 Score on Test data is: {:.2f}\".format(F1_score))\n",
    "print(\"Loss on Test Data is: {:.2f}\".format(TEST_LOSS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "fig, (ax1) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "fig.suptitle('Loss and accuracy for HAN Model.')\n",
    "\n",
    "# accuracy Plot\n",
    "train_accu, = ax1[0].plot(range(1, 21), train_accu_list, label=\"Training Accuracy\")  \n",
    "val_accu, = ax1[0].plot(range(1, 21), val_accu_list, label=\"Validation Accuracy\")  \n",
    "\n",
    "ax1[0].legend(handles=[train_accu, val_accu])\n",
    "ax1[0].set_xlabel(\"Epochs\")\n",
    "ax1[0].set_ylabel(\"Accuracy\")\n",
    "ax1[0].set_title(\"Accuracy for every Epochs\")\n",
    "ax1[0].set_xticks(range(1, 21))\n",
    "\n",
    "train_loss, = ax1[1].plot(range(1, 21), train_loss_list, label=\"Training Loss\")  \n",
    "val_loss, = ax1[1].plot(range(1, 21), val_loss_list, label=\"Validation Loss\")  \n",
    "\n",
    "ax1[1].legend(handles=[train_loss, val_loss])\n",
    "ax1[1].set_xlabel(\"Epochs\")\n",
    "ax1[1].set_ylabel(\"Loss\")\n",
    "ax1[1].set_title(\"Loss for every Epochs\")\n",
    "ax1[1].set_xticks(range(1, 21))\n",
    "\n",
    "# do not need the third plot.\n",
    "#fig.delaxes(ax2[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
